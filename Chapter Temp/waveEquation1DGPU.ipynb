{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "waveEquation1DGPU.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvPXlma7TM_P",
        "colab_type": "code",
        "outputId": "a65fd387-a511-41c8-89db-c158106018af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.6/dist-packages (2019.1.2)\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.6/dist-packages (from pycuda) (2020.1)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.6/dist-packages (from pycuda) (1.1.2)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (1.4.3)\n",
            "Requirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGcyVc1PCvdn",
        "colab_type": "text"
      },
      "source": [
        "Standard imports.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8vkOSbr0RJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from matplotlib import animation, rc\n",
        "from IPython.display import HTML"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQZThyjxT5Iu",
        "colab_type": "text"
      },
      "source": [
        "PyCUDA imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2W5jwJdT7Ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL2hJsH2UUi9",
        "colab_type": "text"
      },
      "source": [
        "```iDivUp``` function: if ```b``` divides ```a```, then ```a/b``` is returned, otherwise the function returns the integer division between ```a``` and ```b``` summed to 1```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io9xU0t3UVzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################\n",
        "# iDivUp FUNCTION #\n",
        "###################\n",
        "def iDivUp(a, b):\n",
        "    # Round a / b to nearest higher integer value\n",
        "    a = np.int32(a)\n",
        "    b = np.int32(b)\n",
        "    return (a / b + 1) if (a % b != 0) else (a / b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PB97piRGaxO",
        "colab_type": "text"
      },
      "source": [
        "Kernel functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59dHBB1xGfH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BLOCKSIZE = 256\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "\n",
        "#define BLOCKSIZE\t\t%(BBLOCKSIZE)s\n",
        "\n",
        "#define PI\t\t\t\t3.1415926535897932384626433832795028841971693993751058209749445923078164062\n",
        "\n",
        "/********************************/\n",
        "/* PROPAGATION DEVICE FUNCTIONS */\n",
        "/********************************/\n",
        "template<class T>\n",
        "__host__ __device__  T propagatingFunctionStationary(const T x, const T x1, const T x2) { return cos((3 * PI / (x2 - x1)) * x); }\n",
        "\n",
        "template<class T>\n",
        "__host__ __device__  T propagatingFunctionStationaryDerivative(const T x, const T x1, const T x2) { return -(3 * PI / (x2 - x1)) * sin((3 * PI / (x2 - x1)) * x); }\n",
        "\n",
        "/*************************/\n",
        "/* STEP0 DEVICE FUNCTION */\n",
        "/*************************/\n",
        "template<class T>\n",
        "__device__ void setStep0Device(T * __restrict__ d_u1, T * __restrict__ d_u, const T * __restrict__ d_t, const T * __restrict__ d_x, const T v, const T x1, const T x2, const int tid) {\n",
        "  \n",
        "  d_u1[tid] = ((T)0.5) * (propagatingFunctionStationary(d_x[tid] - x1 - v * d_t[0], x1, x2) - \n",
        "\t\t\t\t\t        propagatingFunctionStationary(d_x[tid] - x1 + v * d_t[0], x1, x2));   \n",
        "\td_u[tid] = d_u1[tid]; }\n",
        "\n",
        "/*************************/\n",
        "/* STEP1 DEVICE FUNCTION */\n",
        "/*************************/\n",
        "template<class T>\n",
        "__device__ void setStep1Device(T * __restrict__ d_u1, T * __restrict__ d_u2, T * __restrict__ d_u, const T * __restrict__ d_t, const T * __restrict__ d_x, const T v, const T x1, const T x2, const T alpha, const T dt,\n",
        "\tconst int tid, const int N) {\n",
        "\n",
        "\tif (tid == 0) \t{ \n",
        "\t\td_u2[0] = ((T)0.5) * (propagatingFunctionStationary(-v * d_t[1], x1, x2) - propagatingFunctionStationary(v * d_t[1], x1, x2)); \n",
        "\t\td_u[N + 1] = d_u2[0];\n",
        "\t\treturn; }\n",
        "\tif (tid == N) { \n",
        "\t\td_u2[N] = ((T)0.5) * (propagatingFunctionStationary(x2 - x1 - v * d_t[1], x1, x2) - propagatingFunctionStationary(x2 - x1 + v * d_t[1], x1, x2)); \n",
        "\t\td_u[2 * N + 1] = d_u2[N];\n",
        "\t\treturn;\n",
        "\t}\n",
        "\td_u2[tid] = alpha * alpha * d_u1[tid + 1] / ((T)2) + ((T)1 - alpha * alpha) * d_u1[tid]\n",
        "\t\t\t+ alpha * alpha * d_u1[tid - 1] / ((T)2) - v * dt * ((T)0.5) * (\n",
        "\t\t\tpropagatingFunctionStationaryDerivative(d_x[tid] - x1 - v * d_t[0], x1, x2) +\n",
        "\t\t\tpropagatingFunctionStationaryDerivative(d_x[tid] - x1 + v * d_t[0], x1, x2));\n",
        "\n",
        "\td_u[tid + N + 1] = d_u2[tid]; }\n",
        "\n",
        "/****************************************************/\n",
        "/* UPDATE DEVICE FUNCTION - NO SHARED - NOT WORKING */\n",
        "/****************************************************/\n",
        "template<class T>\n",
        "__device__ void updateDeviceNoSharedNotWorking(T * __restrict__ d_u1, T * __restrict__ d_u2, T * __restrict__ d_u3, T * __restrict__ d_u, const T * __restrict__ d_t, const T * __restrict__ d_x, const T v, const T x1, \n",
        "\t\t\t\t\t\t\t\t\t\t\t   const T x2, const T alpha, const int l, const int tid, const int N) {\n",
        "\n",
        "\tif (tid == 0) {\n",
        "\t\td_u3[0] = ((T)0.5) * (propagatingFunctionStationary(-v * d_t[l + 1], x1, x2) - propagatingFunctionStationary(v * d_t[l + 1], x1, x2));\n",
        "\t\td_u[(l + 1) * (N + 1)] = d_u3[0];\n",
        "\t\td_u1[0] = d_u2[0];\n",
        "\t\td_u2[0] = d_u3[0];\n",
        "\t\treturn;\n",
        "\t}\n",
        "\n",
        "\tif (tid < N) {\n",
        "\t\td_u3[tid] = alpha * alpha * d_u2[tid + 1] + ((T)2) * ((T)1 - alpha * alpha) * d_u2[tid] + alpha * alpha * d_u2[tid - 1] - d_u1[tid];\n",
        "\t\td_u[(l + 1) * (N + 1) + tid] = d_u3[tid];\n",
        "\t\td_u1[tid] = d_u2[tid];\n",
        "\t\td_u2[tid] = d_u3[tid];\n",
        "\t\treturn;\n",
        "\t}\n",
        "\n",
        "\td_u3[N] = ((T)0.5) * (propagatingFunctionStationary(x2 - x1 - v * d_t[l + 1], x1, x2) - propagatingFunctionStationary(x2 - x1 + v * d_t[l + 1], x1, x2));   \n",
        "\td_u[(l + 1) * (N + 1) + N] = d_u3[N];\n",
        "\td_u1[N] = d_u2[N];\n",
        "\td_u2[N] = d_u3[N]; }\n",
        "\n",
        "/**************************************/\n",
        "/* UPDATE DEVICE FUNCTION - NO SHARED */\n",
        "/**************************************/\n",
        "template<class T>\n",
        "__device__ void updateDeviceNoShared(T * __restrict__ d_u1, T * __restrict__ d_u2, T * __restrict__ d_u3, T * __restrict__ d_u, const T * __restrict__ d_t, const T * __restrict__ d_x, const T v, const T x1,\n",
        "\tconst T x2, const T alpha, const int l, const int tid, const int N) {\n",
        "    \n",
        "    if (tid == 0) {\n",
        "\t\td_u3[0] = ((T)0.5) * (propagatingFunctionStationary(-v * d_t[l + 1], x1, x2) - propagatingFunctionStationary(v * d_t[l + 1], x1, x2));\n",
        "\t\td_u[(l + 1) * (N + 1)] = d_u3[0];\n",
        "\t\treturn;\n",
        "\t}\n",
        "\n",
        "\tif (tid < N) {\n",
        "\t\td_u3[tid] = alpha * alpha * d_u2[tid + 1] + ((T)2) * ((T)1 - alpha * alpha) * d_u2[tid] + alpha * alpha * d_u2[tid - 1] - d_u1[tid];\n",
        "\t\td_u[(l + 1) * (N + 1) + tid] = d_u3[tid];\n",
        "\t\treturn;\n",
        "\t}\n",
        "\n",
        "\td_u3[N] = ((T)0.5) * (propagatingFunctionStationary(x2 - x1 - v * d_t[l + 1], x1, x2) - propagatingFunctionStationary(x2 - x1 + v * d_t[l + 1], x1, x2));\n",
        "\td_u[(l + 1) * (N + 1) + N] = d_u3[N]; }\n",
        "\n",
        "\n",
        "/***********************************/\n",
        "/* UPDATE DEVICE FUNCTION - SHARED */\n",
        "/***********************************/\n",
        "template<class T>\n",
        "__device__ void updateDeviceShared(T * __restrict__ d_u1, T * __restrict__ d_u2, T * __restrict__ d_u3, T * __restrict__ d_u, const T * __restrict__ d_t, const T * __restrict__ d_x, const T v, const T x1,\n",
        "\tconst T x2, const T alpha, const int l, const int tid, const int N) {\n",
        "\n",
        "\t__shared__ T d_u2_temp[BLOCKSIZE + 2];\n",
        "\n",
        "\td_u2_temp[threadIdx.x + 1] = d_u2[tid];\n",
        "\n",
        "\tif ((threadIdx.x == 0) && ((tid >= 1))) { d_u2_temp[0] = d_u2[tid - 1]; }\t\t\t\t\t\t\t\t\t\t\n",
        "\n",
        "\tif ((threadIdx.x == 0) && ((tid + BLOCKSIZE) < (N + 1))) { d_u2_temp[BLOCKSIZE + 1] = d_u[tid + BLOCKSIZE]; }\t\n",
        "\n",
        "\t__syncthreads();\n",
        "\t\n",
        "\tif (tid == 0) {\n",
        "\t\td_u3[0] = ((T)0.5) * (propagatingFunctionStationary(-v * d_t[l + 1], x1, x2) - propagatingFunctionStationary(v * d_t[l + 1], x1, x2));\n",
        "\t\td_u[(l + 1) * (N + 1)] = d_u3[0];\n",
        "\t\treturn;\n",
        "\t}\n",
        "\n",
        "\tif (tid < N) {\n",
        "\t\td_u3[tid] = alpha * alpha * d_u2_temp[threadIdx.x + 2] + ((T)2) * ((T)1 - alpha * alpha) * d_u2_temp[threadIdx.x + 1] + alpha * alpha * d_u2_temp[threadIdx.x] - d_u1[tid];\n",
        "\t\td_u[(l + 1) * (N + 1) + tid] = d_u3[tid];\n",
        "\t\treturn;\n",
        "\t}\n",
        "\n",
        "\td_u3[N] = ((T)0.5) * (propagatingFunctionStationary(x2 - x1 - v * d_t[l + 1], x1, x2) - propagatingFunctionStationary(x2 - x1 + v * d_t[l + 1], x1, x2));\n",
        "\td_u[(l + 1) * (N + 1) + N] = d_u3[N]; }\n",
        "         \n",
        "/***************************/\n",
        "/* EXTERN GLOBAL FUNCTIONS */\n",
        "/***************************/\n",
        "extern \"C\" {\n",
        "\n",
        "// --- Step0\n",
        "__global__ void setStep0Kernel(float * __restrict__ d_u1, float * __restrict__ d_u, const float * __restrict__ d_t, const float * __restrict__ d_x, const float v, const float x1, const float x2, const int N) {\n",
        "\n",
        "\tconst int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "\tif (tid >= N + 1) return;\n",
        "\n",
        "\tsetStep0Device(d_u1, d_u, d_t, d_x, v, x1, x2, tid); }\n",
        "\n",
        "// --- Step1\n",
        "__global__ void setStep1Kernel(float * __restrict__ d_u1, float * __restrict__ d_u2, float * __restrict__ d_u, const float * __restrict__ d_t, const float * __restrict__ d_x, const float v, const float x1, const float x2, const float alpha, const float dt,\n",
        "\tconst int N) {\n",
        "\n",
        "\tconst int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "\tif (tid >= N + 1) return;\n",
        "\n",
        "  setStep1Device(d_u1, d_u2, d_u, d_t, d_x, v, x1, x2, alpha, dt,\ttid, N);\n",
        "}\n",
        "\n",
        "// --- Update kernel no shared not working\n",
        "__global__ void updateKernelNoSharedNotWorking(float * __restrict__ d_u1, float * __restrict__ d_u2, float * __restrict__ d_u3, float * __restrict__ d_u, const float * __restrict__ d_t, const float * __restrict__ d_x, const float v, const float x1, \n",
        "\t\t\t\t\t\t\t\t\t\t\t   const float x2, const float alpha, const int l, const int N) {\n",
        "\n",
        "\tconst int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "\tif (tid >= N + 1) return;\n",
        "\n",
        "  updateDeviceNoSharedNotWorking(d_u1, d_u2, d_u3, d_u, d_t, d_x, v, x1, x2, alpha, l, tid, N); }\n",
        "\n",
        "// --- Update kernel no shared \n",
        "__global__ void updateKernelNoShared(float * __restrict__ d_u1, float * __restrict__ d_u2, float * __restrict__ d_u3, float * __restrict__ d_u, const float * __restrict__ d_t, const float * __restrict__ d_x, const float v, const float x1,\n",
        "\tconst float x2, const float alpha, const int l, const int N) {\n",
        "\n",
        "\tconst int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "\tif (tid >= N + 1) return;\n",
        "\n",
        "  updateDeviceNoShared(d_u1, d_u2, d_u3, d_u, d_t, d_x, v, x1, x2, alpha, l, tid, N);\n",
        "}\n",
        "\n",
        "// --- Update kernel shared\n",
        "__global__ void updateKernelShared(float * __restrict__ d_u1, float * __restrict__ d_u2, float * __restrict__ d_u3, float * __restrict__ d_u, const float * __restrict__ d_t, const float * __restrict__ d_x, const float v, const float x1,\n",
        "\tconst float x2, const float alpha, const int l, const int N) {\n",
        "\n",
        "\tconst int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "\tif (tid >= N + 1) return;\n",
        "\n",
        "  updateDeviceShared(d_u1, d_u2, d_u3, d_u, d_t, d_x, v, x1, x2, alpha, l, tid, N); }\n",
        "\n",
        "}\n",
        "\"\"\" % { \"BBLOCKSIZE\" : BLOCKSIZE }, no_extern_c = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5X475VvauCX",
        "colab_type": "text"
      },
      "source": [
        "Set references to the ```__global__``` functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwqqsrbvayon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "setStep0                    = mod.get_function(\"setStep0Kernel\")\n",
        "setStep1                    = mod.get_function(\"setStep1Kernel\")\n",
        "updateNoSharedNotWorking    = mod.get_function(\"updateKernelNoSharedNotWorking\")\n",
        "updateNoShared              = mod.get_function(\"updateKernelNoShared\")\n",
        "updateShared                = mod.get_function(\"updateKernelShared\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOzBdtuTGFNz",
        "colab_type": "text"
      },
      "source": [
        "Solution function. Rows span time, columns span space. We have ```M + 1``` rows: ```M``` iterations + ```1``` initial condition. We have ```N + 1``` columns: ```N``` discretization points + ```1``` boundary condition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMh7ovzDTLrI",
        "colab_type": "text"
      },
      "source": [
        "Leapfrog."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzeFj39QGCrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def leapfrogStationary(d_x, d_t, v, xmin, xmax, alpha):\n",
        "\n",
        "  # --- Allocate device memory space for solution\n",
        "  d_u  = cuda.mem_alloc((N + 1) * (M + 1) * 4)\n",
        "  d_u1 = cuda.mem_alloc((N + 1)           * 4)\n",
        "  d_u2 = cuda.mem_alloc((N + 1)           * 4)\n",
        "  d_u3 = cuda.mem_alloc((N + 1)           * 4)\n",
        "  # --- Set memory to zero\n",
        "  cuda.memset_d32(d_u , 0x00, (N + 1) * (M + 1))\n",
        "  cuda.memset_d32(d_u1, 0x00, (N + 1)          )\n",
        "  cuda.memset_d32(d_u2, 0x00, (N + 1)          )\n",
        "  cuda.memset_d32(d_u3, 0x00, (N + 1)          )\n",
        "  # u     = np.zeros(((M + 1), N + 1))\n",
        "\n",
        "  blockDim  = (BLOCKSIZE, 1, 1)\n",
        "  gridDim   = (int(iDivUp(N + 1, BLOCKSIZE)), 1, 1)\n",
        "\n",
        "  # --- Step0\n",
        "  setStep0(d_u1, d_u, d_t, d_x, np.float32(v), np.float32(xmin), np.float32(xmax), np.int32(N), block = blockDim, grid = gridDim)\n",
        "\n",
        "  # --- Step1\n",
        "  setStep1(d_u1, d_u2, d_u, d_t, d_x, np.float32(v), np.float32(xmin), np.float32(xmax), np.float32(alpha), np.float32(dt), np.int32(N), block = blockDim, grid = gridDim)\n",
        "\n",
        "  for l in range(1, M - 1):\n",
        "\n",
        "    updateShared(d_u1, d_u2, d_u3, d_u, d_t, d_x, np.float32(v), np.float32(xmin), np.float32(xmax), np.float32(alpha), np.int32(l), np.int32(N), block = blockDim, grid = gridDim)\n",
        "    # updateNoShared(d_u1, d_u2, d_u3, d_u, d_t, d_x, np.float32(v), np.float32(xmin), np.float32(xmax), np.float32(alpha), np.int32(l), np.int32(N), block = blockDim, grid = gridDim)\n",
        "    # updateNoSharedNotWorking(d_u1, d_u2, d_u3, d_u, d_t, d_x, np.float32(v), np.float32(xmin), np.float32(xmax), np.float32(alpha), np.int32(l), np.int32(N), block = blockDim, grid = gridDim)\n",
        "\n",
        "    cuda.memcpy_dtod(d_u1, d_u2, (N + 1) * 4)\n",
        "    cuda.memcpy_dtod(d_u2, d_u3, (N + 1) * 4)\n",
        "\n",
        "  return d_u"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bIk3RivDurk",
        "colab_type": "text"
      },
      "source": [
        "Parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9ejBh_edwIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xmin  = 0                                    # --- Left boundary of the simulation domain\n",
        "xmax  = 2. * np.pi                           # --- Right boundary of the simulation domain\n",
        "t_0   = 0.                                   # --- Initial time\n",
        "t_f   = 15.                                  # --- Final time\n",
        "M     = 200                                  # --- Number of time steps\n",
        "N     = 100                                  # --- Number of space mesh points\n",
        "v     = 0.5                                  # --- Wave speed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E457WDUbEHbe",
        "colab_type": "text"
      },
      "source": [
        "Space-time discretization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vjpz_BHD72j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, dx = np.linspace(xmin, xmax, N + 1, retstep = True, dtype = np.float32)\n",
        "\n",
        "t, dt = np.linspace(t_0, t_f, M + 1, retstep = True, dtype = np.float32)\n",
        "            \n",
        "alpha = v * dt / dx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pG00JiOgYeq",
        "colab_type": "text"
      },
      "source": [
        "Moving discretization to the device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuHBQxWDgZGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_x = cuda.mem_alloc(x.nbytes)\n",
        "d_t = cuda.mem_alloc(t.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(d_x, x)\n",
        "cuda.memcpy_htod(d_t, t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vENOyoRPIiNI",
        "colab_type": "text"
      },
      "source": [
        "Compute solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjIqacaXhC9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_u = leapfrogStationary(d_x, d_t, v, xmin, xmax, alpha)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAYD1mfUg2Ex",
        "colab_type": "text"
      },
      "source": [
        "Copy the solution from device to host."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU0uHHOig2jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u = np.zeros((M + 1, N + 1), dtype = np.float32)\n",
        "cuda.memcpy_dtoh(u, d_u)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp1HsE5CqmSu",
        "colab_type": "text"
      },
      "source": [
        "Propagating distribution and its derivative. They serve as reference and as initial condition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e32qZWjqoqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def propagatingFunctionStationary(x, xmin, xmax):\n",
        "    return np.cos((2. * np.pi / ((2. / 3.) * (xmax - xmin))) * x)\n",
        "\n",
        "def propagatingFunctionStationaryDerivative(x, xmin, xmax):\n",
        "  return -(2. * np.pi / ((2. / 3.) * (xmax - xmin))) * np.sin((2. * np.pi / ((2. / 3.) * (xmax - xmin))) * x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkuKnsiuqa-3",
        "colab_type": "text"
      },
      "source": [
        "Define reference solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVrVxyQ3qboO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, T = np.meshgrid(x, t)           \n",
        "\n",
        "uFW  =  0.5 * propagatingFunctionStationary(X - xmin - v * T, xmin, xmax);\n",
        "uBW  = -0.5 * propagatingFunctionStationary(X - xmin + v * T, xmin, xmax);\n",
        "\n",
        "uRef = 0.5 * (propagatingFunctionStationary(X - xmin - v * T, xmin, xmax) - propagatingFunctionStationary(X - xmin + v * T, xmin, xmax));  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1zirKVxLZ7H",
        "colab_type": "text"
      },
      "source": [
        "Animation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX2p5Q30wU6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.close()\n",
        "\n",
        "ax.set_xlim(( xmin, xmax))\n",
        "ax.set_ylim(( -1.1, 1.1))\n",
        "\n",
        "line1, = ax.plot([], [], lw = 2, color = \"r\")\n",
        "line2, = ax.plot([], [], lw = 2, color = \"g\")\n",
        "line3, = ax.plot([], [], lw = 2, color = \"c\")\n",
        "line4, = ax.plot([], [], lw = 2, color = \"b\", marker = \"o\")\n",
        "\n",
        "def animate(i):\n",
        "    global x\n",
        "    global u, uRef, uFW, uBW\n",
        "    yRef = uRef[i]\n",
        "    yFW  = uFW[i]\n",
        "    yBW  = uBW[i]\n",
        "    y    = u[i]\n",
        "    line1.set_data(x, yRef)\n",
        "    line2.set_data(x, yFW)\n",
        "    line3.set_data(x, yBW)\n",
        "    line4.set_data(x, y)\n",
        "    return (line1, line2, line3, line4)\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, frames = N + 1, interval = 20)\n",
        "anim.save('leapfrog.mp4', fps = 30, extra_args=['-vcodec', 'libx264'])\n",
        "rc('animation', html = 'jshtml') \n",
        "anim"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}